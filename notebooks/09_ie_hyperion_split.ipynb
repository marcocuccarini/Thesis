{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union Hyperion datatset\n",
    "Creating a datast in which the text is the union of the spans to avoid issues and noisy data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/processed/union/hyperion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    text = row.Testo\n",
    "    \n",
    "    if pd.isna(text):\n",
    "        sample['Stralci'].append(row.Stralcio)\n",
    "        sample['Repertori'].append(row.Repertorio)\n",
    "\n",
    "    else:\n",
    "        sample = {}\n",
    "        sample['Testo'] = text\n",
    "        sample['Stralci'] = [row.Stralcio]\n",
    "        sample['Repertori'] = [row.Repertorio]\n",
    "        dataset.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IE_dict = {\n",
    "                'Testo': [sample['Testo'] for sample in dataset],\n",
    "                'Stralci': [sample['Stralci'] for sample in dataset],\n",
    "                'Repertori': [sample['Repertori'] for sample in dataset]\n",
    "\n",
    "            }\n",
    "df = pd.DataFrame(IE_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv ('../data/processed/union/ie_hyperion.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Union dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (15332, 3)\n",
      "TRAIN Dataset: (12266, 3)\n",
      "TEST Dataset: (3066, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_df = df.sample(frac=train_size, random_state=200)\n",
    "test_df = df.drop(train_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv ('../data/processed/splitted_union/ie_hyperion_train.csv', index = False, header=True)\n",
    "test_df.to_csv ('../data/processed/splitted_union/ie_hyperion_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple spans dataset\n",
    "Dataset with more than 2 spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spans_train_set = train_df[train_df.Stralci.str.len() > 1]\n",
    "\n",
    "multiple_spans_train_set.to_csv ('../data/processed/splitted_union/ie_s2_hyperion_train.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5416\n"
     ]
    }
   ],
   "source": [
    "multiple_spans_test_set = test_df[test_df.Stralci.str.len() > 1]\n",
    "\n",
    "multiple_spans_test_set.to_csv ('../data/processed/splitted_union/ie_s2_hyperion_test.csv', index = False, header=True)\n",
    "\n",
    "count = 0\n",
    "for row in multiple_spans_test_set.itertuples():\n",
    "    count += len(row.Stralci)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets Hyperion dataset\n",
    "Dividing articles from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10767\n",
      "4565\n"
     ]
    }
   ],
   "source": [
    "tweets_dataset = []\n",
    "articles_dataset = []\n",
    "for sample in dataset:\n",
    "    tweet_flag = False\n",
    "    if len(sample['Testo']) < 280:\n",
    "        tweet_flag = True\n",
    "    if tweet_flag:\n",
    "        tweets_dataset.append(sample)\n",
    "    else:\n",
    "        articles_dataset.append(sample)\n",
    "print(len(tweets_dataset))\n",
    "print(len(articles_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IE_dict = {\n",
    "                'Testo': [sample['Testo'] for sample in tweets_dataset],\n",
    "                'Stralci': [sample['Stralci'] for sample in tweets_dataset],\n",
    "                'Repertori': [sample['Repertori'] for sample in tweets_dataset]\n",
    "\n",
    "            }\n",
    "df = pd.DataFrame(IE_dict)\n",
    "\n",
    "train_size = 0.8\n",
    "train_df = df.sample(frac=train_size, random_state=200)\n",
    "test_df = df.drop(train_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
    "\n",
    "train_df.to_csv ('../data/processed/splitted_union/ie_tweets_hyperion_train.csv', index = False, header=True)\n",
    "test_df.to_csv ('../data/processed/splitted_union/ie_tweets_hyperion_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (4565, 3)\n",
      "TRAIN Dataset: (3652, 3)\n",
      "TEST Dataset: (913, 3)\n"
     ]
    }
   ],
   "source": [
    "IE_dict = {\n",
    "                'Testo': [sample['Testo'] for sample in articles_dataset],\n",
    "                'Stralci': [sample['Stralci'] for sample in articles_dataset],\n",
    "                'Repertori': [sample['Repertori'] for sample in articles_dataset]\n",
    "\n",
    "            }\n",
    "df = pd.DataFrame(IE_dict)\n",
    "\n",
    "train_size = 0.8\n",
    "train_df = df.sample(frac=train_size, random_state=200)\n",
    "test_df = df.drop(train_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
    "\n",
    "train_df.to_csv ('../data/processed/splitted_union/ie_articles_hyperion_train.csv', index = False, header=True)\n",
    "test_df.to_csv ('../data/processed/splitted_union/ie_articles_hyperion_test.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "925faa4ca74e07e17e8807425b2222c7f6b32ec00bddad3c89cd83a7cae0c688"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
