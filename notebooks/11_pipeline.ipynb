{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(sys.path[0]) + '/src')\n",
    "from ast import literal_eval\n",
    "from datasets.ie_hyperion_dataset import find_word_bounds, clean_text\n",
    "\n",
    "df = pd.read_csv('../data/processed/pipeline/test/ie_hyperion.csv', converters={'Stralci': literal_eval, 'Repertori': literal_eval})\n",
    "#df = df.head(50)\n",
    "df['Testo'] = df['Testo'].map(clean_text)\n",
    "df['Stralci'] = df['Stralci'].map(lambda x: [clean_text(s) for s in x])\n",
    "df['Bounds'] = df.apply(lambda x: find_word_bounds(x['Stralci'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(A, B):\n",
    "    start = max(A[0], B[0])\n",
    "    end = min(A[1], B[1])\n",
    "    if(start > end):\n",
    "        return 0\n",
    "    return end - start + 1\n",
    "\n",
    "\n",
    "def C(pred_bound:tuple, gt_bound:tuple, pred_rep:str, gt_rep:str, norm_factor:int) -> float:\n",
    "    if pred_rep != gt_rep:\n",
    "        return 0\n",
    "    x = intersection(pred_bound, gt_bound)\n",
    "    return x / norm_factor\n",
    "\n",
    "def precision(pred_bounds:list, gt_bounds:list, pred_reps:list, gt_reps:list) -> float:\n",
    "    curr_sum = 0\n",
    "    for i in range(len(pred_bounds)):\n",
    "        for j in range(len(gt_bounds)):\n",
    "            curr_sum += C(pred_bounds[i], gt_bounds[j], pred_reps[i], gt_reps[j], pred_bounds[i][1] - pred_bounds[i][0] + 1)\n",
    "    return curr_sum / len(pred_bounds)\n",
    "\n",
    "def recall(pred_bounds:list, gt_bounds:list, pred_reps:list, gt_reps:list) -> float:\n",
    "    curr_sum = 0\n",
    "    for i in range(len(pred_bounds)):\n",
    "        for j in range(len(gt_bounds)):\n",
    "            curr_sum += C(pred_bounds[i], gt_bounds[j], pred_reps[i], gt_reps[j], gt_bounds[j][1] - gt_bounds[j][0] + 1)\n",
    "    return curr_sum / len(gt_bounds)\n",
    "\n",
    "def f1(prec:float, rec:float) -> float:\n",
    "    if prec and rec:\n",
    "        return 2 * ((prec * rec)/(prec + rec))\n",
    "    return 0\n",
    "\n",
    "def IoU(pred_bounds:list, gt_bounds:list, pred_reps:list, gt_reps:list) -> float:\n",
    "    curr_sum = 0\n",
    "    for i in range(len(pred_bounds)):\n",
    "        for j in range(len(gt_bounds)):\n",
    "            curr_sum += C(pred_bounds[i], gt_bounds[j], pred_reps[i], gt_reps[j], max(pred_bounds[i][1], gt_bounds[j][1]) - min(pred_bounds[i][0], gt_bounds[j][0]) + 1)\n",
    "    return curr_sum / len(pred_bounds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(bounds:list, reps:list):\n",
    "    norm_bounds = []\n",
    "    norm_reps = []\n",
    "    \n",
    "    for i in range(len(bounds)):\n",
    "        if norm_reps and norm_reps[-1] == reps[i]:\n",
    "            norm_bounds[-1] = (norm_bounds[-1][0], bounds[i][1])\n",
    "        else:\n",
    "            norm_bounds.append(bounds[i])\n",
    "            norm_reps.append(reps[i])\n",
    "    return pd.Series([norm_bounds, norm_reps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nltk_segmenter import NLTKSegmenter\n",
    "\n",
    "\n",
    "nltk_seg = NLTKSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(nltk_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_rep import BertRep\n",
    "\n",
    "bert_rep = BertRep()\n",
    "df['Repertori_predetti'] = df['Stralci_predetti'].map(bert_rep.predict).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29351827761622273\n",
      "0.30353414371873155\n",
      "0.2886571763709411\n",
      "0.2427361186838209\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_segmenter import BertSegmenter\n",
    "\n",
    "bert_seg = BertSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(bert_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_rep import BertRep\n",
    "\n",
    "bert_rep = BertRep()\n",
    "df['Repertori_predetti'] = df['Stralci_predetti'].map(bert_rep.predict).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK + CLS ottimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michele/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from models.nltk_segmenter import NLTKSegmenter\n",
    "\n",
    "\n",
    "nltk_seg = NLTKSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(nltk_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def optimal_rep(pred_bounds: list, gt_bounds:list, reps:list):\n",
    "    opt_reps = []\n",
    "    for b in pred_bounds:\n",
    "        opt = np.argmax([intersection(b, x) for x in gt_bounds])\n",
    "        opt_reps.append(reps[opt])\n",
    "    return opt_reps\n",
    "\n",
    "\n",
    "df['Repertori_predetti'] = df.apply(lambda x: optimal_rep(x['Bounds_predetti'], x['Bounds'], x['Repertori']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9467603903230071\n",
      "0.8812328602948418\n",
      "0.9019201022407155\n",
      "0.6179222972511701\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9445165782946999\n",
      "0.8812201295162867\n",
      "0.9010714143714191\n",
      "0.9390283325194846\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + CLS ottimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_segmenter import BertSegmenter\n",
    "\n",
    "bert_seg = BertSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(bert_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def optimal_rep(pred_bounds: list, gt_bounds:list, reps:list):\n",
    "    opt_reps = []\n",
    "    for b in pred_bounds:\n",
    "        opt = np.argmax([intersection(b, x) for x in gt_bounds])\n",
    "        opt_reps.append(reps[opt])\n",
    "    return opt_reps\n",
    "\n",
    "\n",
    "df['Repertori_predetti'] = df.apply(lambda x: optimal_rep(x['Bounds_predetti'], x['Bounds'], x['Repertori']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375757679460751\n",
      "0.842296912752431\n",
      "0.8705571397106444\n",
      "0.6313146682518852\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936950124028952\n",
      "0.8420045995256696\n",
      "0.8706209693315267\n",
      "0.8993033577261793\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK + CLS random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michele/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from models.nltk_segmenter import NLTKSegmenter\n",
    "\n",
    "\n",
    "nltk_seg = NLTKSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(nltk_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import seed\n",
    "from datasets.hyperion_dataset import decode_labels\n",
    "\n",
    "seed(1464)\n",
    "\n",
    "def rand_cls(n:int) -> list:\n",
    "    cls = [randint(0,22) for _ in range(n)]\n",
    "    return decode_labels(cls)\n",
    "\n",
    "df['Repertori_predetti'] = df.apply(lambda x: rand_cls(len(x['Bounds_predetti'])), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044407641437046515\n",
      "0.042256647929365884\n",
      "0.040739674733738025\n",
      "0.030087476034809615\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04440255948854607\n",
      "0.042256647929365884\n",
      "0.04057405105963676\n",
      "0.0302209534449937\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + CLS random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_segmenter import BertSegmenter\n",
    "\n",
    "bert_seg = BertSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(bert_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import seed\n",
    "from datasets.hyperion_dataset import decode_labels\n",
    "\n",
    "seed(1464)\n",
    "\n",
    "def rand_cls(n:int) -> list:\n",
    "    cls = [randint(0,22) for _ in range(n)]\n",
    "    return decode_labels(cls)\n",
    "\n",
    "df['Repertori_predetti'] = df.apply(lambda x: rand_cls(len(x['Bounds_predetti'])), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043717936953035906\n",
      "0.04044134381853343\n",
      "0.03915551941264637\n",
      "0.02943148860330272\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043453629536277356\n",
      "0.04044134381853343\n",
      "0.03903155818616637\n",
      "0.029874160151226164\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "925faa4ca74e07e17e8807425b2222c7f6b32ec00bddad3c89cd83a7cae0c688"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
