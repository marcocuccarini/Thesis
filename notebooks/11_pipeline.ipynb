{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(sys.path[0]) + '/src')\n",
    "from ast import literal_eval\n",
    "from datasets.ie_hyperion_dataset import find_word_bounds, clean_text\n",
    "\n",
    "df = pd.read_csv('../data/processed/pipeline/test/ie_hyperion.csv', converters={'Stralci': literal_eval, 'Repertori': literal_eval})\n",
    "#df = df.head(50)\n",
    "df['Testo'] = df['Testo'].map(clean_text)\n",
    "df['Stralci'] = df['Stralci'].map(lambda x: [clean_text(s) for s in x])\n",
    "df['Bounds'] = df.apply(lambda x: find_word_bounds(x['Stralci'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(A, B):\n",
    "    start = max(A[0], B[0])\n",
    "    end = min(A[1], B[1])\n",
    "    if(start > end):\n",
    "        return 0\n",
    "    return end - start + 1\n",
    "\n",
    "\n",
    "def C(pred_bound:tuple, gt_bound:tuple, pred_rep:str, gt_rep:str, norm_factor:int) -> float:\n",
    "    if pred_rep != gt_rep:\n",
    "        return 0\n",
    "    x = intersection(pred_bound, gt_bound)\n",
    "    return x / norm_factor\n",
    "\n",
    "def precision(pred_bounds:list, gt_bounds:list, pred_reps:list, gt_reps:list) -> float:\n",
    "    curr_sum = 0\n",
    "    for i in range(len(pred_bounds)):\n",
    "        for j in range(len(gt_bounds)):\n",
    "            curr_sum += C(pred_bounds[i], gt_bounds[j], pred_reps[i], gt_reps[j], pred_bounds[i][1] - pred_bounds[i][0] + 1)\n",
    "    return curr_sum / len(pred_bounds)\n",
    "\n",
    "def recall(pred_bounds:list, gt_bounds:list, pred_reps:list, gt_reps:list) -> float:\n",
    "    curr_sum = 0\n",
    "    for i in range(len(pred_bounds)):\n",
    "        for j in range(len(gt_bounds)):\n",
    "            curr_sum += C(pred_bounds[i], gt_bounds[j], pred_reps[i], gt_reps[j], gt_bounds[j][1] - gt_bounds[j][0] + 1)\n",
    "    return curr_sum / len(gt_bounds)\n",
    "\n",
    "def f1(prec:float, rec:float) -> float:\n",
    "    if prec and rec:\n",
    "        return 2 * ((prec * rec)/(prec + rec))\n",
    "    return 0\n",
    "\n",
    "def IoU(pred_bounds:list, gt_bounds:list, pred_reps:list, gt_reps:list) -> float:\n",
    "    curr_sum = 0\n",
    "    for i in range(len(pred_bounds)):\n",
    "        for j in range(len(gt_bounds)):\n",
    "            curr_sum += C(pred_bounds[i], gt_bounds[j], pred_reps[i], gt_reps[j], max(pred_bounds[i][1], gt_bounds[j][1]) - min(pred_bounds[i][0], gt_bounds[j][0]) + 1)\n",
    "    return curr_sum / len(pred_bounds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(bounds:list, reps:list):\n",
    "    norm_bounds = []\n",
    "    norm_reps = []\n",
    "    \n",
    "    for i in range(len(bounds)):\n",
    "        if norm_reps and norm_reps[-1] == reps[i]:\n",
    "            norm_bounds[-1] = (norm_bounds[-1][0], bounds[i][1])\n",
    "        else:\n",
    "            norm_bounds.append(bounds[i])\n",
    "            norm_reps.append(reps[i])\n",
    "    return pd.Series([norm_bounds, norm_reps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## segmenter ottimo + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_rep import BertRep\n",
    "\n",
    "bert_rep = BertRep()\n",
    "df['Repertori_predetti'] = df['Stralci'].map(bert_rep.predict).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT SEG + BERT\n",
      "0.41755630448791553\n",
      "0.4175581330692732\n",
      "0.4175572070638188\n",
      "0.4175545675676947\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print('OPT SEG + BERT')\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPT SEG + BERT norm\n",
      "0.419067510965262\n",
      "0.4175526557238897\n",
      "0.4175703029401396\n",
      "0.419067510965262\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print('OPT SEG + BERT norm')\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michele/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from models.nltk_segmenter import NLTKSegmenter\n",
    "\n",
    "\n",
    "nltk_seg = NLTKSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(nltk_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_rep import BertRep\n",
    "\n",
    "bert_rep = BertRep()\n",
    "df['Repertori_predetti'] = df['Stralci_predetti'].map(bert_rep.predict).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004718615576747079\n",
      "0.0046154013551244055\n",
      "0.004519172355641398\n",
      "0.004012308739479754\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print('NLTK + BERT')\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print('BERT + BERT norm')\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_segmenter import BertSegmenter\n",
    "\n",
    "bert_seg = BertSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(bert_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_rep import BertRep\n",
    "\n",
    "bert_rep = BertRep()\n",
    "df['Repertori_predetti'] = df['Stralci_predetti'].map(bert_rep.predict).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37369420684781746\n",
      "0.36555002400034536\n",
      "0.3623481486134643\n",
      "0.33127296517234917\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print('BERT + BERT')\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009532639896573889\n",
      "0.010532637982794465\n",
      "0.009407292121459798\n",
      "0.009437041903007072\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print('BERT + BERT norm')\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK + CLS ottimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michele/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from models.nltk_segmenter import NLTKSegmenter\n",
    "\n",
    "\n",
    "nltk_seg = NLTKSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(nltk_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def optimal_rep(pred_bounds: list, gt_bounds:list, reps:list):\n",
    "    opt_reps = []\n",
    "    for b in pred_bounds:\n",
    "        opt = np.argmax([intersection(b, x) for x in gt_bounds])\n",
    "        opt_reps.append(reps[opt])\n",
    "    return opt_reps\n",
    "\n",
    "\n",
    "df['Repertori_predetti'] = df.apply(lambda x: optimal_rep(x['Bounds_predetti'], x['Bounds'], x['Repertori']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9467603903230071\n",
      "0.8812328602948418\n",
      "0.9019201022407155\n",
      "0.6179222972511701\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print('NLTK + CLS ottimo')\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9445165782946999\n",
      "0.8812201295162867\n",
      "0.9010714143714191\n",
      "0.9390283325194846\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print('NLTK + CLS ottimo norm')\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + CLS ottimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_segmenter import BertSegmenter\n",
    "\n",
    "bert_seg = BertSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(bert_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def optimal_rep(pred_bounds: list, gt_bounds:list, reps:list):\n",
    "    opt_reps = []\n",
    "    for b in pred_bounds:\n",
    "        opt = np.argmax([intersection(b, x) for x in gt_bounds])\n",
    "        opt_reps.append(reps[opt])\n",
    "    return opt_reps\n",
    "\n",
    "\n",
    "df['Repertori_predetti'] = df.apply(lambda x: optimal_rep(x['Bounds_predetti'], x['Bounds'], x['Repertori']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375757679460751\n",
      "0.842296912752431\n",
      "0.8705571397106444\n",
      "0.6313146682518852\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print('BERT + CLS ottimo')\n",
    "\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936950124028952\n",
      "0.8420045995256696\n",
      "0.8706209693315267\n",
      "0.8993033577261793\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print('BERT + CLS ottimo norm')\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK + CLS random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michele/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from models.nltk_segmenter import NLTKSegmenter\n",
    "\n",
    "\n",
    "nltk_seg = NLTKSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(nltk_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import seed\n",
    "from datasets.hyperion_dataset import decode_labels\n",
    "\n",
    "seed(1464)\n",
    "\n",
    "def rand_cls(n:int) -> list:\n",
    "    cls = [randint(0,22) for _ in range(n)]\n",
    "    return decode_labels(cls)\n",
    "\n",
    "df['Repertori_predetti'] = df.apply(lambda x: rand_cls(len(x['Bounds_predetti'])), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044407641437046515\n",
      "0.042256647929365884\n",
      "0.040739674733738025\n",
      "0.030087476034809615\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print('NLTK + CLS random')\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04440255948854607\n",
      "0.042256647929365884\n",
      "0.04057405105963676\n",
      "0.0302209534449937\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print('NLTK + CLS random norm')\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + CLS random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.bert_segmenter import BertSegmenter\n",
    "\n",
    "bert_seg = BertSegmenter()\n",
    "df['Stralci_predetti'] = df['Testo'].map(bert_seg.predict).values.tolist()\n",
    "df['Bounds_predetti'] = df.apply(lambda x: find_word_bounds(x['Stralci_predetti'], x['Testo']), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import seed\n",
    "from datasets.hyperion_dataset import decode_labels\n",
    "\n",
    "seed(1464)\n",
    "\n",
    "def rand_cls(n:int) -> list:\n",
    "    cls = [randint(0,22) for _ in range(n)]\n",
    "    return decode_labels(cls)\n",
    "\n",
    "df['Repertori_predetti'] = df.apply(lambda x: rand_cls(len(x['Bounds_predetti'])), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043717936953035906\n",
      "0.04044134381853343\n",
      "0.03915551941264637\n",
      "0.02943148860330272\n"
     ]
    }
   ],
   "source": [
    "df['Precision'] =  df.apply(lambda x: precision(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['Recall'] =  df.apply(lambda x: recall(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "df['F1'] =  df.apply(lambda x: f1(x['Precision'], x['Recall']), axis=1)\n",
    "df['IoU'] =  df.apply(lambda x: IoU(x['Bounds_predetti'], x['Bounds'], x['Repertori_predetti'], x['Repertori']), axis=1)\n",
    "\n",
    "print('BERT + CLS random')\n",
    "\n",
    "print(df['Precision'].mean())\n",
    "print(df['Recall'].mean())\n",
    "print(df['F1'].mean())\n",
    "print(df['IoU'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043453629536277356\n",
      "0.04044134381853343\n",
      "0.03903155818616637\n",
      "0.029874160151226164\n"
     ]
    }
   ],
   "source": [
    "df[['Norm_bounds', 'Norm_rep']] =  df.apply(lambda x: normalize(x['Bounds_predetti'], x['Repertori_predetti']), axis=1)\n",
    "\n",
    "df['Norm_precision'] =  df.apply(lambda x: precision(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_recall'] =  df.apply(lambda x: recall(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "df['Norm_f1'] =  df.apply(lambda x: f1(x['Norm_precision'], x['Norm_recall']), axis=1)\n",
    "df['Norm_IoU'] =  df.apply(lambda x: IoU(x['Norm_bounds'], x['Bounds'], x['Norm_rep'], x['Repertori']), axis=1)\n",
    "\n",
    "print('BERT + CLS random norm')\n",
    "print(df['Norm_precision'].mean())\n",
    "print(df['Norm_recall'].mean())\n",
    "print(df['Norm_f1'].mean())\n",
    "print(df['Norm_IoU'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RISULTATI da cluster\n",
    "NLTK + BERT\n",
    "0.2990602818274286\n",
    "0.29751360751204853\n",
    "0.2897168291168118\n",
    "0.20986743884372597\n",
    "\n",
    "NLTK + BERT norm\n",
    "0.2881645483627048\n",
    "0.29751360751204853\n",
    "0.2828495318043233\n",
    "0.23518775892093524\n",
    "\n",
    "BERT + BERT\n",
    "0.3175951768074362\n",
    "0.3013790273821301\n",
    "0.29867822523716175\n",
    "0.2523689405834198\n",
    "\n",
    "BERT + BERT norm\n",
    "0.3147392277664459\n",
    "0.3013577509082085\n",
    "0.29698474595848295\n",
    "0.2675877796407899\n",
    "\n",
    "NLTK + CLS ottimo\n",
    "0.9467603903230075\n",
    "0.8812328602948415\n",
    "0.9019201022407156\n",
    "0.6179222972511671\n",
    "\n",
    "NLTK + CLS ottimo norm\n",
    "0.9445165782947008\n",
    "0.8812201295162867\n",
    "0.9010714143714188\n",
    "0.9390283325194851\n",
    "\n",
    "BERT + CLS ottimo\n",
    "0.9463897708207414\n",
    "0.8688017717594765\n",
    "0.8917464576750034\n",
    "0.6666620091429322\n",
    "\n",
    "BERT + CLS ottimo norm\n",
    "0.9470870050957066\n",
    "0.8689860748196476\n",
    "0.892520978540389\n",
    "0.9293125056746196\n",
    "\n",
    "NLTK + CLS random\n",
    "0.044407641437046494\n",
    "0.04225664792936588\n",
    "0.04073967473373807\n",
    "0.03008747603480959\n",
    "\n",
    "NLTK + CLS random norm\n",
    "0.04440255948854607\n",
    "0.04225664792936588\n",
    "0.040574051059636795\n",
    "0.030220953444993686\n",
    "\n",
    "BERT + CLS random\n",
    "0.03947437441425662\n",
    "0.038680462145539794\n",
    "0.03676656673673848\n",
    "0.027945803398262345\n",
    "\n",
    "BERT + CLS random norm\n",
    "0.039539754353300004\n",
    "0.03867744216535087\n",
    "0.03667237117688916\n",
    "0.02827673305407843"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "925faa4ca74e07e17e8807425b2222c7f6b32ec00bddad3c89cd83a7cae0c688"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
