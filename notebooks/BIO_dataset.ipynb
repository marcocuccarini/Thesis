{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Original_csv/Hyperion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def find_word_bounds(spans: list, text: str) -> list:\n",
    "    bounds = []\n",
    "    end = 0\n",
    "    for span in spans:\n",
    "        s = span.translate(str.maketrans('', '', string.punctuation))\n",
    "        word_list = s.split()\n",
    "        text_list = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        try:\n",
    "            start = text_list.index(word_list[0], end)\n",
    "        except:\n",
    "            if not bounds:\n",
    "                start = 0\n",
    "            else:\n",
    "                \n",
    "                start = bounds[-1][1] + 1\n",
    "        end = start + len(word_list) - 1\n",
    "            \n",
    "        bounds.append((start, end))\n",
    "    return bounds\n",
    "\n",
    "def find_subword_bounds(spans: list, text: str, tokenizer) -> list:\n",
    "    bounds = []\n",
    "    end = 0\n",
    "    text_tok_list =tokenizer.tokenize(text)\n",
    "    print(len(text_tok_list))\n",
    "    for span in spans:\n",
    "        tok_list = tok.tokenize(span)\n",
    "        if not bounds:\n",
    "            start = 0\n",
    "        else:\n",
    "            start = bounds[-1][1] +1\n",
    "        for i in range(start, len(text_tok_list)):\n",
    "            if tok_list[-1] == text_tok_list[i]:\n",
    "                end = i\n",
    "                break\n",
    "        bounds.append((start, end))\n",
    "    print(bounds[-1][1])\n",
    "    return bounds\n",
    "\n",
    "def IE_gen(bounds:list) -> str:\n",
    "    end = [bound[1] for bound in bounds]\n",
    "    x = ['E' if i in end else 'I' for i in range(end[-1]+1)]\n",
    "    return ''.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "52\n",
      "11\n",
      "10\n",
      "46\n",
      "45\n",
      "225\n",
      "169\n",
      "124\n",
      "121\n",
      "237\n",
      "192\n",
      "34\n",
      "33\n",
      "25\n",
      "17\n",
      "27\n",
      "26\n",
      "11\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    text = row.Testo\n",
    "    if pd.isna(text):\n",
    "        sample['Stralci'].append(row.Stralcio)\n",
    "        sample['Repertori'].append(row.Repertorio)\n",
    "        \n",
    "    else: \n",
    "        sample = {}\n",
    "        sample['Testo'] = text\n",
    "        sample['Stralci'] = [row.Stralcio]\n",
    "        \n",
    "        sample['Repertori'] = [row.Repertorio]\n",
    "        dataset.append(sample)\n",
    "        \n",
    "tok = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n",
    "for sample in dataset[:10]:\n",
    "    sample['Bounds'] = find_word_bounds(sample['Stralci'], sample['Testo'])\n",
    "    sample['Subword_Bounds'] = find_subword_bounds(sample['Stralci'], sample['Testo'], tok)\n",
    "    sample['Tags'] = IE_gen(sample['Bounds'])\n",
    "    sample['Subword_Tags'] = IE_gen(sample['Subword_Bounds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Testo': '\"Ha suscitato scandalo la proposta di Salvini di riaprire le chiese a Pasqua. Non altrettanto scandalo aveva suscitato l’idea di Renzi di riaprire le librerie, né quella della Confindustria di tenere aperte le imprese. Il leader della Lega mescola certo con troppa superficialità il profano della politica con il sacro della preghiera. E le esigenze di distanziamento sociale rendono evidentemente impossibile ciò che chiede. Ma le reazioni che ha ricevuto, quasi sdegnate, fanno riflettere. La paradossale verità è che oggi cultura e industria ci appaiono strumenti di rinascita e riscatto più idonei della religione. Il processo di secolarizzazione, anche nel Paese più cattolico d’Europa, ha ormai espunto la fede dal dibattito pubblico, come se fosse un sentimento privato, rispettato sì, ma in definitiva inutile al corpo sociale.\\nInvece il sacro è sempre stato un formidabile strumento di tenuta e coesione delle società umane, e forse è addirittura nato per questo scopo. Émile Durkheim, il fondatore della sociologia, definiva la religione «una cosa eminentemente sociale», il modo con cui le comunità degli uomini, attraverso credenze e riti, costruivano la propria rappresentazione collettiva.\"', 'Stralci': ['Ha suscitato scandalo la proposta di Salvini di riaprire le chiese a Pasqua.', 'Non altrettanto scandalo aveva suscitato l’idea di Renzi di riaprire le librerie, né quella della Confindustria di tenere aperte le imprese.', 'Il leader della Lega mescola certo con troppa superficialità il profano della politica con il sacro della preghiera.', ' E le esigenze di distanziamento sociale rendono evidentemente impossibile ciò che chiede.', 'Ma le reazioni che ha ricevuto fanno riflettere.', ', quasi sdegnate, ', 'La paradossale verità è che oggi cultura e industria ci appaiono strumenti di rinascita e riscatto più idonei della religione.', 'Il processo di secolarizzazione ha ormai espunto la fede dal dibattito pubblico', ', anche nel Paese più cattolico d’Europa,', ', come se fosse un sentimento privato, rispettato sì, ma in definitiva inutile al corpo sociale.', 'Invece il sacro è sempre stato un formidabile strumento di tenuta e coesione delle società umane,', 'e forse è addirittura nato per questo scopo.', 'Émile Durkheim, il fondatore della sociologia, definiva la religione «una cosa eminentemente sociale», il modo con cui le comunità degli uomini, attraverso credenze e riti, costruivano la propria rappresentazione collettiva.\"'], 'Repertori': ['sancire', 'valutazione', 'conferma', 'conferma', 'implicazione', 'giudizio', 'giudizio', 'sancire', 'specificazione', 'commento', 'contrapposizione', 'possibilità', 'considerazione'], 'Bounds': [(0, 12), (13, 33), (34, 51), (52, 63), (64, 71), (72, 73), (74, 93), (94, 105), (106, 111), (112, 126), (127, 142), (143, 150), (151, 180)], 'Subword_Bounds': [(0, 0), (1, 15), (16, 23), (24, 31), (32, 41), (42, 60), (61, 74), (75, 133), (134, 134), (135, 141), (142, 144), (145, 152), (153, 169)], 'Tags': 'IIIIIIIIIIIIEIIIIIIIIIIIIIIIIIIIIEIIIIIIIIIIIIIIIIIEIIIIIIIIIIIEIIIIIIIEIEIIIIIIIIIIIIIIIIIIIEIIIIIIIIIIIEIIIIIEIIIIIIIIIIIIIIEIIIIIIIIIIIIIIIEIIIIIIIEIIIIIIIIIIIIIIIIIIIIIIIIIIIIIE', 'Subword_Tags': 'EIIIIIIIIIIIIIIEIIIIIIIEIIIIIIIEIIIIIIIIIEIIIIIIIIIIIIIIIIIIEIIIIIIIIIIIIIEIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIEEIIIIIIEIIEIIIIIIIEIIIIIIIIIIIIIIIIE'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8789\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j=0\n",
    "while j<len(dataset):\n",
    "\n",
    "    x = len(dataset[j]['Subword_Tags'])\n",
    "    y = len(tok.tokenize(dataset[j]['Testo']))\n",
    "    if x != y:\n",
    "        i += 1\n",
    "        del dataset[j]\n",
    "        j-=1\n",
    "    j += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6543\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for idx, sample in enumerate(dataset):\n",
    "    x = len(sample['Subword_Tags'])\n",
    "    y = len(tok.tokenize(sample['Testo']))\n",
    "    if x != y:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "IE_dict = {\n",
    "    'Testo' : [sample['Testo'] for sample in dataset],\n",
    "    'Tokens' : [tok.tokenize(sample['Testo']) for sample in dataset],\n",
    "    'Subword_Tags' : [sample['Subword_Tags'] for sample in dataset],\n",
    "    'Subword_bounds' : [sample['Subword_Bounds'] for sample in dataset],\n",
    "    'Bounds' : [sample['Bounds'] for sample in dataset],\n",
    "    'Repertori' : [sample['Repertori'] for sample in dataset]\n",
    "}\n",
    "IE_df = pd.DataFrame(IE_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Testo             Dunque vediamo se ho capito: Conte le canta a ...\n",
       "Tokens            [dunque, vediamo, se, ho, capito, [UNK], conte...\n",
       "Subword_Tags      IIIIIEIIIIIIIEIIIIIIIIIIEEIIIIIIIIIIIIIIIEIIII...\n",
       "Subword_bounds    [(0, 5), (6, 13), (14, 24), (25, 25), (26, 41)...\n",
       "Bounds            [(0, 4), (5, 12), (13, 22), (23, 37), (38, 44)...\n",
       "Repertori         [dichiarazione di intenti, sancire, giustifica...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IE_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IE_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "LABELS = [\n",
    "                'I',\n",
    "                'E'\n",
    "        ]\n",
    "\n",
    "def encode_labels(labels_list):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(LABELS)\n",
    "    return le.transform(labels_list)\n",
    "\n",
    "\n",
    "class IE_Hyperion_dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer_name):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df['Testo'].iloc[idx]\n",
    "        encoding = self.tokenizer(text,\n",
    "                            #is_pretokenized=True, \n",
    "                            return_special_tokens_mask=True, \n",
    "                            add_special_tokens=True,\n",
    "                            return_attention_mask=True,\n",
    "                            padding='max_length',\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        labels = encode_labels(list(self.df['Subword_Tags'].iloc[idx]))\n",
    "        \n",
    "        encoded_labels = np.ones(len(encoding['input_ids']), dtype=int) * -100\n",
    "        i=0\n",
    "        for idx, e in enumerate(encoding['special_tokens_mask']):\n",
    "            if e == 0:\n",
    "                # overwrite label\n",
    "                encoded_labels[idx] = labels[i]\n",
    "                i+=1\n",
    "        \n",
    "        \n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        return item\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-multilingual-cased\"\n",
    "train_size = 0.8\n",
    "train_df = IE_df.sample(frac=train_size,random_state=200)\n",
    "test_df = IE_df.drop(train_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_size = 0.2\n",
    "val_df = train_df.sample(frac=val_size,random_state=200)\n",
    "train_df = train_df.drop(val_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(IE_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"VALIDATION Dataset: {}\".format(val_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
    "\n",
    "train_dataset = IE_Hyperion_dataset(train_df, model_name)\n",
    "val_dataset = IE_Hyperion_dataset(val_df, model_name) \n",
    "test_dataset = IE_Hyperion_dataset(test_df, model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, label in zip(train_dataset.tokenizer.convert_ids_to_tokens(train_dataset[0][\"input_ids\"]), train_dataset[0][\"labels\"]):\n",
    "  print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "#Deterministic mode\n",
    "def seed_everything(seed=1464):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "def plot_loss(loss, val_loss):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.xticks(range(1,len(loss)+1))\n",
    "    plt.plot(range(1,len(loss)+1), loss, label='train')\n",
    "    plt.plot(range(1,len(val_loss)+1), val_loss, label='val')\n",
    "    plt.title('loss')\n",
    "    plt.legend()\n",
    "    #plt.savefig('loss.png')\n",
    "    return fig\n",
    "\n",
    "def plot_f1(f1, val_f1):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.xticks(range(1,len(f1)+1))\n",
    "    plt.plot(range(1,len(f1)+1), f1, label='train')\n",
    "    plt.plot(range(1,len(val_f1)+1), val_f1, label='val')\n",
    "    plt.title('f1')\n",
    "    plt.legend()\n",
    "    #plt.savefig('f1.png')\n",
    "    return fig\n",
    "\n",
    "def plot_confusion_matrix(y_true, pred, labels):\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y_true, pred, display_labels=labels, normalize='true', values_format='.2f')\n",
    "    disp.plot(cmap=\"Blues\", values_format='.2g',xticks_rotation='vertical', ax=ax)\n",
    "    return disp.figure_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "class NeptuneLogger():\n",
    "    def __init__(self) -> None:\n",
    "        #Neptune initialization\n",
    "        self.run = neptune.init(\n",
    "            project=\"mibo8/Rep\",\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmZmRkYThiZi1mZGNlLTRlMTktODQwNS1hNWFlMWQ2Mjc4N2IifQ==\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from torch.nn import utils\n",
    "\n",
    "import torchmetrics\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import  AdamW\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "\n",
    "import neptune.new as neptune\n",
    "\n",
    "\n",
    "class IE_MPTrainer():\n",
    "    def __init__(self, batch_size, lr, n_epochs) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = lr\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "        self.logger = NeptuneLogger()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def fit(self, model, train_dataset, val_dataset):\n",
    "        self.logger.run['model'] = model_name\n",
    "        \n",
    "        params_info = {\n",
    "            'learning_rate' : self.learning_rate,\n",
    "            'batch_size' : self.batch_size,\n",
    "            'n_epochs' : self.n_epochs\n",
    "        }\n",
    "        #self.logger.run['params'] = params_info\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        #----------TRAINING\n",
    "\n",
    "        # Measure the total training time for the whole run.\n",
    "        total_t0 = time.time()\n",
    "\n",
    "        epochs_train_loss = []\n",
    "        epochs_val_loss = []\n",
    "\n",
    "\n",
    "        epochs = self.n_epochs\n",
    "\n",
    "        # Creation of Pytorch DataLoaders with shuffle=True for the traing phase\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        validation_dataloader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        #Adam algorithm optimized for tranfor architectures\n",
    "        optimizer = AdamW(model.parameters(), lr=self.learning_rate)\n",
    "        #scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=300)\n",
    "\n",
    "        # Scaler for mixed precision\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        # Setup for training with gpu\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        model.to(device)\n",
    "\n",
    "        # For each epoch...\n",
    "        for epoch_i in range(0, epochs):\n",
    "            \n",
    "            # ========================================\n",
    "            #               Training\n",
    "            # ========================================\n",
    "            \n",
    "            # Perform one full pass over the training set.\n",
    "\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            print('Training...')\n",
    "\n",
    "\n",
    "            # Measure how long the training epoch takes.\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Reset the total loss for this epoch.\n",
    "            total_train_loss = 0\n",
    "\n",
    "            # Put the model into training mode: Dropout layers are active\n",
    "            model.train()\n",
    "            \n",
    "            # For each batch of training data...\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "                # Progress update every 40 batches.\n",
    "                if step % 10 == 0 and not step == 0:\n",
    "                    # Compute time in minutes.\n",
    "                    elapsed = format_time(time.time() - t0)\n",
    "                    \n",
    "                    # Report progress.\n",
    "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "                # Unpack this training batch from the dataloader. \n",
    "                #\n",
    "                #  copy each tensor to the GPU using the 'to()' method\n",
    "                #\n",
    "                # 'batch' contains three pytorch tensors:\n",
    "                #   [0]: input ids \n",
    "                #   [1]: attention masks\n",
    "                #   [2]: labels \n",
    "                b_input_ids = batch['input_ids'].to(device)\n",
    "                b_input_mask = batch['attention_mask'].to(device)\n",
    "                b_labels = batch['labels'].to(device)\n",
    "\n",
    "                # clear any previously calculated gradients before performing a\n",
    "                # backward pass\n",
    "                model.zero_grad()  \n",
    "\n",
    "\n",
    "                # Perform a forward pass in mixed precision\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(b_input_ids, \n",
    "                                    attention_mask=b_input_mask, \n",
    "                                    labels=b_labels)\n",
    "                \n",
    "                    loss = outputs[0]\n",
    "                    logits = outputs[1]\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                logits = logits.detach().cpu()\n",
    "                label_ids = b_labels.to('cpu')\n",
    "\n",
    "                # Perform a backward pass to compute the gradients in MIXED precision\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Accumulate the training loss over all of the batches so that we can\n",
    "                # calculate the average loss at the end.\n",
    "                total_train_loss += loss.item()\n",
    "\n",
    "                # Unscales the gradients of optimizer's assigned params in-place before the gradient clipping\n",
    "                scaler.unscale_(optimizer)\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This helps and prevent the \"exploding gradients\" problem.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                # Update parameters and take a step using the computed gradient in MIXED precision\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                #scheduler.step()\n",
    "\n",
    "            # Compute the average loss over all of the batches.\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "            epochs_train_loss.append(avg_train_loss)\n",
    "            \n",
    "            # Measure how long this epoch took.\n",
    "            training_time = format_time(time.time() - t0)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "            print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "            # ========================================\n",
    "            #               Validation\n",
    "            # ========================================\n",
    "            # After the completion of each training epoch, measure performance on\n",
    "            # the validation set.\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\")\n",
    "\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Put the model in evaluation mode: the dropout layers behave differently\n",
    "            model.eval()\n",
    "\n",
    "            total_val_loss = 0\n",
    "\n",
    "            # Evaluate data for one epoch\n",
    "            for batch in validation_dataloader:\n",
    "                \n",
    "                # Unpack this training batch from our dataloader. \n",
    "                #\n",
    "                # copy each tensor to the GPU using the 'to()' method\n",
    "                #\n",
    "                # 'batch' contains three pytorch tensors:\n",
    "                #   [0]: input ids \n",
    "                #   [1]: attention masks\n",
    "                #   [2]: labels \n",
    "                b_input_ids = batch['input_ids'].to(device)\n",
    "                b_input_mask = batch['attention_mask'].to(device)\n",
    "                b_labels = batch['labels'].to(device)\n",
    "                \n",
    "                # Tell pytorch not to bother with constructing the compute graph during\n",
    "                # the forward pass, since this is only needed for training.\n",
    "                with torch.no_grad():        \n",
    "\n",
    "                    # Forward pass, calculate logits\n",
    "                    # argmax(logits) = argmax(Softmax(logits))\n",
    "                    outputs = model(b_input_ids, \n",
    "                                        attention_mask=b_input_mask,\n",
    "                                        labels=b_labels)\n",
    "                    loss = outputs[0]\n",
    "                    logits = outputs[1]\n",
    "                    \n",
    "                # Accumulate the validation loss.\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                logits = logits.detach().cpu()\n",
    "                label_ids = b_labels.to('cpu')\n",
    "\n",
    "            print('VALIDATION: ')\n",
    "            \n",
    "            # Compute the average loss over all of the batches.\n",
    "            avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "            epochs_val_loss.append(avg_val_loss)\n",
    "            \n",
    "            # Measure how long the validation run took.\n",
    "            validation_time = format_time(time.time() - t0)\n",
    "            \n",
    "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "            print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        loss_fig = plot_loss(epochs_train_loss, epochs_val_loss)\n",
    "\n",
    "        self.logger.run[\"loss\"].upload(neptune.types.File.as_image(loss_fig))\n",
    "        print(\"\")\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "        print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def test(self, model, test_dataset):\n",
    "        # ========================================\n",
    "        #               Test\n",
    "        # ========================================\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        # Setup for testing with gpu\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Test...\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Save prediction for confusion matrix\n",
    "        pred = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_test_loss = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in test_dataloader:\n",
    "            b_input_ids = batch['input_ids'].to(device)\n",
    "            b_input_mask = batch['attention_mask'].to(device)\n",
    "            b_labels = batch['labels'].to(device)\n",
    "            b_special_tokens_mask = batch['special_tokens_mask'].to(device)\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logits\n",
    "                # argmax(logits) = argmax(Softmax(logits))\n",
    "                outputs = model(b_input_ids, \n",
    "                                        attention_mask=b_input_mask,\n",
    "                                        labels=b_labels)\n",
    "                loss = outputs[0]\n",
    "                logits = outputs[1]\n",
    "                \n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu() #shape (batch_size, seq_len, num_labels)\n",
    "            label_ids = b_labels.to('cpu')\n",
    "\n",
    "            batch_pred = logits.softmax(dim=-1)\n",
    "            full_pred =  batch_pred.argmax(dim=-1)\n",
    "            \n",
    "\n",
    "            for i, sample_pred in enumerate(full_pred):\n",
    "                active_pred = []\n",
    "                for j, e in enumerate(b_special_tokens_mask[i]):\n",
    "                    if(e==0):\n",
    "                        active_pred.append(int(sample_pred[j]))\n",
    "                pred.append(active_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "        #self.logger.run['test/loss'] = avg_test_loss\n",
    "        test_time = format_time(time.time() - t0)\n",
    "\n",
    "        \n",
    "        print(\"  Test Loss: {0:.2f}\".format(avg_test_loss))\n",
    "        print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-5\n",
    "batch_size = 2\n",
    "n_epochs = 1\n",
    "trainer = IE_MPTrainer(batch_size, learning_rate, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataset, val_dataset)\n",
    "pred = trainer.test(model,test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_bounds(pred:list):\n",
    "    dataset_bounds = []\n",
    "    for e in pred:\n",
    "        start = 0\n",
    "        end = 0\n",
    "        bounds = []\n",
    "        for i, tok_pred in enumerate(e):\n",
    "            if tok_pred == 0:\n",
    "                end = i\n",
    "                bounds.append((start, end))\n",
    "                start = end + 1\n",
    "        dataset_bounds.append(bounds)\n",
    "    return dataset_bounds\n",
    "        \n",
    "\n",
    "bert_pred = pred_to_bounds(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# A è B sono tupe con i bound dello span\n",
    "def IoU(A, B):\n",
    "    if A == B:\n",
    "        return 1\n",
    "    start = max(A[0], B[0])\n",
    "    end = min(A[1], B[1])\n",
    "    if(start > end):\n",
    "        return 0\n",
    "    intersection = end - start\n",
    "    return intersection / (A[1] - A[0] + B[1] - B[0] - intersection)\n",
    "\n",
    "def compute_IoUs(pred_bounds, gt_spans):\n",
    "    IoUs = []\n",
    "    for gt_bounds in gt_spans:\n",
    "        IoUs.append(IoU(pred_bounds, gt_bounds)) \n",
    "    return IoUs\n",
    "\n",
    "def normalize(text_spans_dict, gt_spans):\n",
    "    normalized = []\n",
    "    for i in range(len(text_spans_dict)):\n",
    "        #normalized is not empty\n",
    "        if normalized:\n",
    "            if normalized[-1]['Repertorio'] == text_spans_dict[i]['Repertorio']:\n",
    "                new_span = (normalized[-1]['Bounds'][0], text_spans_dict[i]['Bounds'][1])\n",
    "                new_span_features = {\n",
    "                    'Bounds' : new_span, \n",
    "                    'IoU' : None,\n",
    "                    'Repertorio' : text_spans_dict[i]['Repertorio']\n",
    "                    }\n",
    "                del normalized[-1]\n",
    "                normalized.append(new_span_features)\n",
    "            else:\n",
    "                normalized.append(text_spans_dict[i])\n",
    "        else:\n",
    "            normalized.append(text_spans_dict[i])\n",
    "        \n",
    "    \n",
    "    for i in range(len(normalized)):\n",
    "        normalized[i]['IoU'] = max(compute_IoUs(normalized[i]['Bounds'], gt_spans['Subword_bounds']))\n",
    "    return normalized\n",
    "\n",
    "metrics = []\n",
    "normalized_metrics = []\n",
    "for i, pred_bounds in enumerate(bert_pred):\n",
    "    text_IoUs = []\n",
    "    for pred_span in pred_bounds:\n",
    "        IoUs = compute_IoUs(pred_span, test_df.iloc[i]['Subword_bounds'])\n",
    "        best = np.argmax(IoUs)\n",
    "        span_features = {\n",
    "            'Bounds' : pred_span, \n",
    "            'IoU' : IoUs[best],\n",
    "            'Repertorio' : test_df.iloc[i]['Repertori'][best]\n",
    "            }\n",
    "\n",
    "        text_IoUs.append(span_features)\n",
    "    metrics.append(text_IoUs)\n",
    "    normalized_metrics.append(normalize(text_IoUs, test_df.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------------------')\n",
    "print('Risultati labels GT e stralci non uniti')\n",
    "\n",
    "\n",
    "n_spans = 0\n",
    "for e in test_df['Subword_bounds']:\n",
    "    n_spans += len(e)\n",
    "print('Numero stralci nel dataset:', str(n_spans))\n",
    "\n",
    "n_spans = 0\n",
    "for e in metrics:\n",
    "    n_spans += len(e)\n",
    "print('Numero stralci predetti:', str(n_spans))\n",
    "\n",
    "mean = 0\n",
    "long_spans = 0\n",
    "min_lenght = 0\n",
    "perfect_spans =0\n",
    "for text in metrics:\n",
    "    for span in text:\n",
    "        if span['Bounds'][1] - span['Bounds'][0] >= min_lenght:\n",
    "            long_spans += 1\n",
    "            mean += span['IoU']\n",
    "            if span['IoU'] == 1:\n",
    "                perfect_spans += 1\n",
    "perfect_spans_perc = perfect_spans / long_spans\n",
    "mean_IoU = mean / long_spans\n",
    "print('Numero stralci con lunghezza minima = ', str(min_lenght), ': ', str(long_spans))\n",
    "print('Media IoU:', str(mean_IoU))\n",
    "print('Percentuale span perfetti: ', str(perfect_spans_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------------------')\n",
    "print('Risultati labels GT e stralci uniti')\n",
    "\n",
    "\n",
    "n_spans = 0\n",
    "for e in test_df['Subword_bounds']:\n",
    "    n_spans += len(e)\n",
    "print('Numero stralci nel dataset:', str(n_spans))\n",
    "\n",
    "n_spans = 0\n",
    "for e in normalized_metrics:\n",
    "    n_spans += len(e)\n",
    "print('Numero stralci predetti:', str(n_spans))\n",
    "\n",
    "mean = 0\n",
    "long_spans = 0\n",
    "min_lenght = 0\n",
    "perfect_spans =0\n",
    "for text in normalized_metrics:\n",
    "    for span in text:\n",
    "        if span['Bounds'][1] - span['Bounds'][0] >= min_lenght:\n",
    "            long_spans += 1\n",
    "            mean += span['IoU']\n",
    "            if span['IoU'] == 1:\n",
    "                perfect_spans += 1\n",
    "perfect_spans_perc = perfect_spans / long_spans\n",
    "mean_IoU = mean / long_spans\n",
    "print('Numero stralci con lunghezza minima = ', str(min_lenght), ': ', str(long_spans))\n",
    "print('Media IoU:', str(mean_IoU))\n",
    "print('Percentuale span perfetti: ', str(perfect_spans_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('MiBo/RepML')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dataset = []\n",
    "\n",
    "\n",
    "for i, span_group in enumerate(bert_pred):\n",
    "  text_features = {}\n",
    "  text_features['Testo'] = test_df.iloc[i]['Testo']\n",
    "  text_features['Stralci'] = [span.lower() for span in span_group]\n",
    "  text_features['Bounds'] = bert_pred[i]\n",
    "  predicted_dataset.append(text_features)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "531bf1ddd0b9ee64f0e2ebd6527c520de4e2159f2ffcc26ba5e4b06431092b93"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
