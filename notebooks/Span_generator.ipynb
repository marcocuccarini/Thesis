{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbVZweEEW1eD"
      },
      "source": [
        "# Span generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Mhe88vKvVjN5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('../data/Original_csv/Hyperion.csv', na_filter=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "N1jTvA17WUsV"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "dataset = []\n",
        "sample = {}\n",
        "\n",
        "for row in df.itertuples():\n",
        "    text = row.Testo\n",
        "    if text and len(text) > 4:\n",
        "        dataset.append(sample)\n",
        "        sample = {}\n",
        "        sample['Testo'] = text\n",
        "        sample['Stralci'] = [row.Stralcio]\n",
        "        sample['Repertori'] = [row.Repertorio]\n",
        "        \n",
        "    else:\n",
        "        sample['Stralci'].append(row.Stralcio)\n",
        "        sample['Repertori'].append(row.Repertorio)\n",
        "del dataset[0]\n",
        "\n",
        "#Find bounds starting froma text\n",
        "def find_char_bounds(spans: list, text: str) -> list:\n",
        "    bounds = []\n",
        "    last_char = 0\n",
        "    for span in spans:\n",
        "        start = text.find(span)\n",
        "        if start == -1:\n",
        "            start = last_char + 1\n",
        "        bounds.append((start, start + len(span)))\n",
        "        last_char = start + len(span)\n",
        "    return bounds\n",
        "\n",
        "def find_word_bounds(spans: list, text: str) -> list:\n",
        "    bounds = []\n",
        "    end = 0\n",
        "    for span in spans:\n",
        "        s = span.translate(str.maketrans('', '', string.punctuation))\n",
        "        word_list = s.split()\n",
        "        text_list = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
        "        try:\n",
        "            start = text_list.index(word_list[0], end)\n",
        "        except:\n",
        "            if not bounds:\n",
        "                start = 0\n",
        "            else:\n",
        "                \n",
        "                start = bounds[-1][1] + 1\n",
        "        end = start + len(word_list) - 1\n",
        "            \n",
        "        bounds.append((start, end))\n",
        "    return bounds\n",
        "\n",
        "\n",
        "for sample in dataset:\n",
        "    #sample['Bounds'] = find_char_bounds(sample['Stralci'], sample['Testo'])\n",
        "    sample['Bounds'] = find_word_bounds(sample['Stralci'], sample['Testo'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUofuB4KWhf3",
        "outputId": "95a850fb-aa28-437f-b07f-d256f2fb399e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/michele/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize\n",
        "import re\n",
        "\n",
        "nltk_pred = []\n",
        "spans_pred = []\n",
        "\n",
        "for sample in dataset:\n",
        "    tokens = sent_tokenize(sample['Testo'])\n",
        "    spans = []\n",
        "    bounds = []\n",
        "    \"\"\"\n",
        "    for x in tokens:\n",
        "        #spans += re.findall('.*?[.:!?;,]', x)\n",
        "        spans += re.split('[]', x)\n",
        "        spans = list(filter(None, spans)) # filter empty strings\n",
        "    \"\"\"\n",
        "    #bounds += find_char_bounds(spans, sample['Testo'])\n",
        "    bounds += find_word_bounds(tokens, sample['Testo'])\n",
        "    nltk_pred.append(bounds)\n",
        "    spans_pred.append(spans) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "r1N5H04_WlbH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# A Ã¨ B sono tupe con i bound dello span\n",
        "def IoU(A, B):\n",
        "    if A == B:\n",
        "        return 1\n",
        "    start = max(A[0], B[0])\n",
        "    end = min(A[1], B[1])\n",
        "    if(start > end):\n",
        "        return 0\n",
        "    intersection = end - start\n",
        "    return intersection / (A[1] - A[0] + B[1] - B[0] - intersection)\n",
        "\n",
        "def compute_IoUs(pred_bounds, gt_spans):\n",
        "    IoUs = []\n",
        "    for gt_bounds in gt_spans:\n",
        "        IoUs.append(IoU(pred_bounds, gt_bounds)) \n",
        "    return IoUs\n",
        "\n",
        "#Input: text_spans_dict = [ {\n",
        "#           'Bounds' : (a,b), \n",
        "#           'IoU' : float,\n",
        "#           'Repertorio': 'string':\n",
        "#           } ]\n",
        "def normalize(text_spans_dict, gt_spans):\n",
        "    normalized = []\n",
        "    for i in range(len(text_spans_dict)):\n",
        "        #normalized is not empty\n",
        "        if normalized:\n",
        "            if normalized[-1]['Repertorio'] == text_spans_dict[i]['Repertorio']:\n",
        "                new_span = (normalized[-1]['Bounds'][0], text_spans_dict[i]['Bounds'][1])\n",
        "                new_span_features = {\n",
        "                    'Bounds' : new_span, \n",
        "                    'IoU' : None,\n",
        "                    'Repertorio' : text_spans_dict[i]['Repertorio']\n",
        "                    }\n",
        "                del normalized[-1]\n",
        "                normalized.append(new_span_features)\n",
        "            else:\n",
        "                normalized.append(text_spans_dict[i])\n",
        "        else:\n",
        "            normalized.append(text_spans_dict[i])\n",
        "        \n",
        "    \n",
        "    for i in range(len(normalized)):\n",
        "        normalized[i]['IoU'] = max(compute_IoUs(normalized[i]['Bounds'], gt_spans['Bounds']))\n",
        "    return normalized\n",
        "    \n",
        "\n",
        "metrics = []\n",
        "normalized_metrics = []\n",
        "for i, pred_bounds in enumerate(nltk_pred):\n",
        "    text_IoUs = []\n",
        "    for pred_span in pred_bounds:\n",
        "        IoUs = compute_IoUs(pred_span, dataset[i]['Bounds'])\n",
        "        best = np.argmax(IoUs)\n",
        "        span_features = {\n",
        "            'Bounds' : pred_span, \n",
        "            'IoU' : IoUs[best],\n",
        "            'Repertorio' : dataset[i]['Repertori'][best]\n",
        "            }\n",
        "\n",
        "        text_IoUs.append(span_features)\n",
        "    metrics.append(text_IoUs)\n",
        "    normalized_metrics.append(normalize(text_IoUs, dataset[i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------\n",
            "Risultati labels GT e stralci non uniti\n",
            "Numero stralci nel dataset: 35471\n",
            "Numero stralci predetti: 64447\n",
            "Numero stralci con lunghezza minima =  0 :  63200\n",
            "Media IoU: 0.3731696813940625\n",
            "Percentuale span perfetti:  0.1818987341772152\n"
          ]
        }
      ],
      "source": [
        "print('----------------------------------------------------------')\n",
        "print('Risultati labels GT e stralci non uniti')\n",
        "\n",
        "\n",
        "n_spans = 0\n",
        "for e in dataset:\n",
        "    n_spans += len(e['Bounds'])\n",
        "print('Numero stralci nel dataset:', str(n_spans))\n",
        "\n",
        "n_spans = 0\n",
        "for e in metrics:\n",
        "    n_spans += len(e)\n",
        "print('Numero stralci predetti:', str(n_spans))\n",
        "\n",
        "mean = 0\n",
        "long_spans = 0\n",
        "min_lenght = 0\n",
        "perfect_spans =0\n",
        "for text in metrics:\n",
        "    for span in text:\n",
        "        if span['Bounds'][1] - span['Bounds'][0] >= min_lenght:\n",
        "            long_spans += 1\n",
        "            mean += span['IoU']\n",
        "            if span['IoU'] == 1:\n",
        "                perfect_spans += 1\n",
        "perfect_spans_perc = perfect_spans / long_spans\n",
        "mean_IoU = mean / long_spans\n",
        "print('Numero stralci con lunghezza minima = ', str(min_lenght), ': ', str(long_spans))\n",
        "print('Media IoU:', str(mean_IoU))\n",
        "print('Percentuale span perfetti: ', str(perfect_spans_perc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBBqubrGWpiv",
        "outputId": "e4aedf5d-7942-4329-9f20-1dcc36da9d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------\n",
            "Risultati labels GT e stralci uniti\n",
            "Numero stralci nel dataset: 35471\n",
            "Numero stralci predetti: 26781\n",
            "Numero stralci con lunghezza minima =  0 :  26469\n",
            "Media IoU: 0.8822384163157678\n",
            "Percentuale span perfetti:  0.7178208470285995\n"
          ]
        }
      ],
      "source": [
        "print('----------------------------------------------------------')\n",
        "print('Risultati labels GT e stralci uniti')\n",
        "\n",
        "\n",
        "n_spans = 0\n",
        "for e in dataset:\n",
        "    n_spans += len(e['Bounds'])\n",
        "print('Numero stralci nel dataset:', str(n_spans))\n",
        "\n",
        "n_spans = 0\n",
        "for e in normalized_metrics:\n",
        "    n_spans += len(e)\n",
        "print('Numero stralci predetti:', str(n_spans))\n",
        "\n",
        "mean = 0\n",
        "long_spans = 0\n",
        "min_lenght = 0\n",
        "perfect_spans =0\n",
        "for text in normalized_metrics:\n",
        "    for span in text:\n",
        "        if span['Bounds'][1] - span['Bounds'][0] >= min_lenght:\n",
        "            long_spans += 1\n",
        "            mean += span['IoU']\n",
        "            if span['IoU'] == 1:\n",
        "                perfect_spans += 1\n",
        "perfect_spans_perc = perfect_spans / long_spans\n",
        "mean_IoU = mean / long_spans\n",
        "print('Numero stralci con lunghezza minima = ', str(min_lenght), ': ', str(long_spans))\n",
        "print('Media IoU:', str(mean_IoU))\n",
        "print('Percentuale span perfetti: ', str(perfect_spans_perc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MI0-t_EWuaO"
      },
      "source": [
        "# Span classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqaKAD_5XLro",
        "outputId": "097feac4-1748-44f6-9d1f-13ba15b71084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/michele/anaconda3/lib/python3.9/site-packages (4.12.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
            "Requirement already satisfied: sacremoses in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
            "Requirement already satisfied: filelock in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/michele/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/michele/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/michele/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/michele/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/michele/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/michele/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: click in /home/michele/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
            "Requirement already satisfied: joblib in /home/michele/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /home/michele/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XwKUZkrBWydE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|ââââââââââ| 703M/703M [01:26<00:00, 8.56MB/s] \n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('MiBo/RepML')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFjoRPxdXZ1a",
        "outputId": "f5cfd1bb-63c8-449c-ec1d-67765c189645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Testo': 'Dunque vediamo se ho capito: Conte le canta a Salvini e alla Meloni, questi reagiscono e le cantano a loro volta a Conte, Mentana si smarca da Conte e finisce con foto celebrativa nelle pagine social della Bestia. Siamo tornati per un attimo alla normalitÃ : meraviglia assoluta!', 'Stralci': ['dunque vediamo se ho capito', ' conte le canta a salvini e alla meloni', ' questi reagiscono e le cantano a loro volta a conte', ' mentana si smarca da conte e finisce con foto celebrativa nelle pagine social della bestia', 'siamo tornati per un attimo alla normalitÃ ', ' meraviglia assoluta'], 'Bounds': [(0, 4), (5, 12), (13, 22), (23, 37), (38, 44), (45, 46)]}\n"
          ]
        }
      ],
      "source": [
        "predicted_dataset = []\n",
        "\n",
        "\n",
        "for i, span_group in enumerate(spans_pred):\n",
        "  text_features = {}\n",
        "  text_features['Testo'] = dataset[i]['Testo']\n",
        "  text_features['Stralci'] = [span.lower() for span in span_group]\n",
        "  text_features['Bounds'] = nltk_pred[i]\n",
        "  predicted_dataset.append(text_features)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oLXXkBsRoh8I"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "LABELS = [\n",
        "                'anticipazione',\n",
        "                'causa',\n",
        "                'commento',\n",
        "                'conferma',\n",
        "                'considerazione',\n",
        "                'contrapposizione',\n",
        "                'deresponsabilizzazione',\n",
        "                'descrizione',\n",
        "                'dichiarazione di intenti',\n",
        "                'generalizzazione',\n",
        "                'giudizio',\n",
        "                'giustificazione',\n",
        "                'implicazione',\n",
        "                'non risposta',\n",
        "                'opinione',\n",
        "                'possibilitÃ ',\n",
        "                'prescrizione',\n",
        "                'previsione',\n",
        "                'proposta',\n",
        "                'ridimensionamento',\n",
        "                'sancire',\n",
        "                'specificazione',\n",
        "                'valutazione'\n",
        "        ]\n",
        "\n",
        "\n",
        "def decode_labels(encoded_labels):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(LABELS)\n",
        "    return le.inverse_transform(encoded_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "04313pMw4p4Y"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import utils\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def predict_labels(text: dict)-> list:\n",
        "  pred = []\n",
        "  if text['Stralci']:\n",
        "    encodings = tokenizer(\n",
        "          text['Stralci'],\n",
        "          max_length=512,\n",
        "          add_special_tokens=True,\n",
        "          return_attention_mask=True,\n",
        "          padding=True,\n",
        "          truncation=True,\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "      \n",
        "  test_dataset = TensorDataset(encodings['input_ids'],encodings['attention_mask'])\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        " \n",
        "  for i, batch in enumerate(test_dataloader):\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      with torch.no_grad():        \n",
        "\n",
        "          # Forward pass, calculate logits\n",
        "          # argmax(logits) = argmax(Softmax(logits))\n",
        "          outputs = model(b_input_ids, \n",
        "                                  attention_mask=b_input_mask)\n",
        "          logits = outputs[0]\n",
        "\n",
        "      logits = logits.detach().cpu()\n",
        "\n",
        "      batch_pred = logits.softmax(dim=1)\n",
        "      pred += batch_pred.argmax(dim=1)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vPf_u-IK73wQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testo:  0\n",
            "testo:  100\n",
            "testo:  200\n",
            "testo:  300\n",
            "testo:  400\n",
            "testo:  500\n",
            "testo:  600\n",
            "testo:  700\n",
            "testo:  800\n",
            "testo:  900\n",
            "testo:  1000\n",
            "testo:  1100\n",
            "testo:  1200\n",
            "testo:  1300\n",
            "testo:  1400\n",
            "testo:  1500\n",
            "testo:  1600\n",
            "testo:  1700\n",
            "testo:  1800\n",
            "testo:  1900\n",
            "testo:  2000\n",
            "testo:  2100\n",
            "testo:  2200\n",
            "testo:  2300\n",
            "testo:  2400\n",
            "testo:  2500\n",
            "testo:  2600\n",
            "testo:  2700\n",
            "testo:  2800\n",
            "testo:  2900\n",
            "testo:  3000\n",
            "testo:  3100\n",
            "testo:  3200\n",
            "testo:  3300\n",
            "testo:  3400\n",
            "testo:  3500\n",
            "testo:  3600\n",
            "testo:  3700\n",
            "testo:  3800\n",
            "testo:  3900\n",
            "testo:  4000\n",
            "testo:  4100\n",
            "testo:  4200\n",
            "testo:  4300\n",
            "testo:  4400\n",
            "testo:  4500\n",
            "testo:  4600\n",
            "testo:  4700\n",
            "testo:  4800\n",
            "testo:  4900\n",
            "testo:  5000\n",
            "testo:  5100\n",
            "testo:  5200\n",
            "testo:  5300\n",
            "testo:  5400\n",
            "testo:  5500\n",
            "testo:  5600\n",
            "testo:  5700\n",
            "testo:  5800\n",
            "testo:  5900\n",
            "testo:  6000\n",
            "testo:  6100\n",
            "testo:  6200\n",
            "testo:  6300\n",
            "testo:  6400\n",
            "testo:  6500\n",
            "testo:  6600\n",
            "testo:  6700\n",
            "testo:  6800\n",
            "testo:  6900\n",
            "testo:  7000\n",
            "testo:  7100\n",
            "testo:  7200\n",
            "testo:  7300\n",
            "testo:  7400\n",
            "testo:  7500\n",
            "testo:  7600\n",
            "testo:  7700\n",
            "testo:  7800\n",
            "testo:  7900\n",
            "testo:  8000\n",
            "testo:  8100\n",
            "testo:  8200\n",
            "testo:  8300\n",
            "testo:  8400\n",
            "testo:  8500\n",
            "testo:  8600\n",
            "testo:  8700\n",
            "testo:  8800\n",
            "testo:  8900\n",
            "testo:  9000\n",
            "testo:  9100\n",
            "testo:  9200\n",
            "testo:  9300\n",
            "testo:  9400\n",
            "testo:  9500\n",
            "testo:  9600\n",
            "testo:  9700\n",
            "testo:  9800\n",
            "testo:  9900\n",
            "testo:  10000\n",
            "testo:  10100\n",
            "testo:  10200\n",
            "testo:  10300\n",
            "testo:  10400\n",
            "testo:  10500\n",
            "testo:  10600\n",
            "testo:  10700\n",
            "testo:  10800\n",
            "testo:  10900\n",
            "testo:  11000\n",
            "testo:  11100\n",
            "testo:  11200\n",
            "testo:  11300\n",
            "testo:  11400\n",
            "testo:  11500\n",
            "testo:  11600\n",
            "testo:  11700\n",
            "testo:  11800\n",
            "testo:  11900\n",
            "testo:  12000\n",
            "testo:  12100\n",
            "testo:  12200\n",
            "testo:  12300\n",
            "testo:  12400\n",
            "testo:  12500\n",
            "testo:  12600\n",
            "testo:  12700\n",
            "testo:  12800\n",
            "testo:  12900\n",
            "testo:  13000\n",
            "testo:  13100\n",
            "testo:  13200\n",
            "testo:  13300\n",
            "testo:  13400\n",
            "testo:  13500\n",
            "testo:  13600\n",
            "testo:  13700\n",
            "testo:  13800\n",
            "testo:  13900\n",
            "testo:  14000\n",
            "testo:  14100\n",
            "testo:  14200\n",
            "testo:  14300\n",
            "testo:  14400\n",
            "testo:  14500\n",
            "testo:  14600\n",
            "testo:  14700\n",
            "testo:  14800\n",
            "testo:  14900\n",
            "testo:  15000\n",
            "testo:  15100\n",
            "testo:  15200\n",
            "testo:  15300\n",
            "testo:  15400\n",
            "testo:  15500\n"
          ]
        }
      ],
      "source": [
        "# Setup for testing with gpu\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "for i, text in enumerate(predicted_dataset):\n",
        "  pred = predict_labels(text)\n",
        "  rep = decode_labels(list(pred))\n",
        "  predicted_dataset[i]['Repertori'] =rep\n",
        "\n",
        "  if i%100==0:\n",
        "    print('testo: ', str(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "cHXeeghItQUW",
        "outputId": "b38040ee-de4d-481a-d2a9-f50431a6a27f"
      },
      "outputs": [],
      "source": [
        "metrics = []\n",
        "normalized_metrics = []\n",
        "for i, sample in enumerate(predicted_dataset):\n",
        "    text_IoUs = []\n",
        "    for j, pred_bounds in enumerate(sample['Bounds']):\n",
        "        IoUs = compute_IoUs(pred_bounds, dataset[i]['Bounds'])\n",
        "        best = np.argmax(IoUs)\n",
        "        span_features = {\n",
        "            'Bounds' : pred_bounds, \n",
        "            'IoU' : IoUs[best],\n",
        "            'Repertorio' : predicted_dataset[i]['Repertori'][j]\n",
        "            }\n",
        "\n",
        "        text_IoUs.append(span_features)\n",
        "    metrics.append(text_IoUs)\n",
        "    normalized_metrics.append(normalize(text_IoUs, dataset[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4HWRrvD-wMUg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero stralci nel dataset: 35471\n",
            "Numero stralci predetti: 151228\n",
            "Numero stralci con lunghezza minima =  0 :  150997\n",
            "Media IoU: 0.13439584113870004\n",
            "Percentuale span perfetti:  0.0458618383146685\n"
          ]
        }
      ],
      "source": [
        "print('----------------------------------------------------------')\n",
        "print('Risultati labels predette e stralci NON uniti')\n",
        "\n",
        "\n",
        "n_spans = 0\n",
        "for e in dataset:\n",
        "    n_spans += len(e['Bounds'])\n",
        "print('Numero stralci nel dataset:', str(n_spans))\n",
        "\n",
        "n_spans = 0\n",
        "for e in metrics:\n",
        "    n_spans += len(e)\n",
        "print('Numero stralci predetti:', str(n_spans))\n",
        "\n",
        "mean = 0\n",
        "long_spans = 0\n",
        "min_lenght = 0\n",
        "perfect_spans =0\n",
        "for text in metrics:\n",
        "    for span in text:\n",
        "        if span['Bounds'][1] - span['Bounds'][0] >= min_lenght:\n",
        "            long_spans += 1\n",
        "            mean += span['IoU']\n",
        "            if span['IoU'] == 1:\n",
        "                perfect_spans += 1\n",
        "perfect_spans_perc = perfect_spans / long_spans\n",
        "mean_IoU = mean / long_spans\n",
        "print('Numero stralci con lunghezza minima = ', str(min_lenght), ': ', str(long_spans))\n",
        "print('Media IoU:', str(mean_IoU))\n",
        "print('Percentuale span perfetti: ', str(perfect_spans_perc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('----------------------------------------------------------')\n",
        "print('Risultati labels predette e stralci uniti')\n",
        "\n",
        "n_spans = 0\n",
        "for e in dataset:\n",
        "    n_spans += len(e['Bounds'])\n",
        "print('Numero stralci nel dataset:', str(n_spans))\n",
        "\n",
        "n_spans = 0\n",
        "for e in normalized_metrics:\n",
        "    n_spans += len(e)\n",
        "print('Numero stralci predetti:', str(n_spans))\n",
        "\n",
        "mean = 0\n",
        "long_spans = 0\n",
        "min_lenght = 0\n",
        "perfect_spans =0\n",
        "for text in normalized_metrics:\n",
        "    for span in text:\n",
        "        if span['Bounds'][1] - span['Bounds'][0] >= min_lenght:\n",
        "            long_spans += 1\n",
        "            mean += span['IoU']\n",
        "            if span['IoU'] == 1:\n",
        "                perfect_spans += 1\n",
        "perfect_spans_perc = perfect_spans / long_spans\n",
        "mean_IoU = mean / long_spans\n",
        "print('Numero stralci con lunghezza minima = ', str(min_lenght), ': ', str(long_spans))\n",
        "print('Media IoU:', str(mean_IoU))\n",
        "print('Percentuale span perfetti: ', str(perfect_spans_perc))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Span_generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
