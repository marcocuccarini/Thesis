{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "LABELS = [\n",
    "            'anticipazione',\n",
    "            'causa',\n",
    "            'commento',\n",
    "            'conferma',\n",
    "            'considerazione',\n",
    "            'contrapposizione',\n",
    "            'deresponsabilizzazione',\n",
    "            'descrizione',\n",
    "            'dichiarazione di intenti',\n",
    "            'generalizzazione',\n",
    "            'giudizio',\n",
    "            'giustificazione',\n",
    "            'implicazione',\n",
    "            'non risposta',\n",
    "            'opinione',\n",
    "            'possibilitÃ ',\n",
    "            'prescrizione',\n",
    "            'previsione',\n",
    "            'proposta',\n",
    "            'ridimensionamento',\n",
    "            'sancire',\n",
    "            'specificazione',\n",
    "            'valutazione'\n",
    "    ]\n",
    "\n",
    "class HyperionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer_name):\n",
    "        #fill_null_features(df)\n",
    "        df = filter_empty_labels(df)\n",
    "        df = to_lower_case(df)\n",
    "        uniform_labels(df)          \n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name) \n",
    "        self.encodings = tokenize(df, tokenizer)\n",
    "        self.labels = encode_labels(df).tolist()    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        \n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)   \n",
    "\n",
    "\n",
    "# Dataset loading and preprocessing\n",
    "def fill_null_features(df):\n",
    "        for c in ['Domanda','Testo']:\n",
    "            for i in range(0,len(df.index)):  \n",
    "                if not df[c][i]:\n",
    "                    j=i\n",
    "                    while j>0: \n",
    "                        j-=1\n",
    "                        if df[c][j]:\n",
    "                            df[c][i] = df[c][j]\n",
    "                            break\n",
    "\n",
    "#Delete examples with empty label\n",
    "def filter_empty_labels(df):\n",
    "    filter = df[\"Repertorio\"] != \"\"\n",
    "    return df[filter]\n",
    "\n",
    "#Convert to lower case\n",
    "def to_lower_case(df):\n",
    "    return df.applymap(str.lower)\n",
    "\n",
    "\n",
    "#Lables uniformation uncased\n",
    "def uniform_labels(df):\n",
    "    df['Repertorio'].replace('implicazioni','implicazione', inplace=True)\n",
    "    df['Repertorio'].replace('previsioni','previsione', inplace=True)\n",
    "\n",
    "def tokenize(df, tokenizer):\n",
    "    return tokenizer(\n",
    "        df['Stralcio'].tolist(),\n",
    "        #df['Domanda'].tolist(),\n",
    "        max_length=512,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "def encode_labels(df):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(LABELS)\n",
    "    return le.transform(df['Repertorio'])\n",
    "\n",
    "def decode_labels(encoded_labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(LABELS)\n",
    "    return le.inverse_transform(encoded_labels)\n",
    "\n",
    "def train_val_split(df, tok_name,  val_perc=0.1):\n",
    "    gb = df.groupby('Repertorio')\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "\n",
    "    for x in gb.groups:\n",
    "        class_df = gb.get_group(x)\n",
    "\n",
    "        # Validation set creation\n",
    "        val = class_df.sample(frac=val_perc)\n",
    "        train = pd.concat([class_df,val]).drop_duplicates(keep=False)\n",
    "\n",
    "        #train_list.append(train.head(500))\n",
    "        train_list.append(train)\n",
    "        val_list.append(val)\n",
    "\n",
    "    train_df = pd.concat(train_list)\n",
    "    val_df = pd.concat(val_list)\n",
    "    return HyperionDataset(train_df, tok_name), HyperionDataset(val_df, tok_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Original_csv/Hyperion.csv', na_filter=False)\n",
    "tok_name = \"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\"\n",
    "\n",
    "train_dataset, val_dataset = train_val_split(df.head(100), tok_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deterministic mode\n",
    "def seed_everything(seed=1464):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "class NeptuneLogger():\n",
    "    def __init__(self) -> None:\n",
    "        #Neptune initialization\n",
    "        self.run = neptune.init(\n",
    "            project=\"mibo8/Rep\",\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmZmRkYThiZi1mZGNlLTRlMTktODQwNS1hNWFlMWQ2Mjc4N2IifQ==\",\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import torchmetrics\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import  AdamW\n",
    "\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, batch_size, lr, n_epochs, ) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = lr\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "        self.logger = NeptuneLogger()\n",
    "\n",
    "        self.metric_collection = torchmetrics.MetricCollection({\n",
    "\n",
    "            'accuracy_micro' : torchmetrics.Accuracy(num_classes=23, multiclass=True, average='micro'),\n",
    "            'accuracy_macro' : torchmetrics.Accuracy(num_classes=23, multiclass=True, average='macro'),\n",
    "            'accuracy_weighted' : torchmetrics.Accuracy(num_classes=23, multiclass=True, average='weighted'),\n",
    "            'accuracy_none' : torchmetrics.Accuracy(num_classes=23, multiclass=True, average='none'),\n",
    "\n",
    "            'f1_micro' : torchmetrics.F1(num_classes=23, multiclass=True, average='micro'),\n",
    "            'f1_macro' : torchmetrics.F1(num_classes=23, multiclass=True, average='macro'),\n",
    "            'f1_weighted' : torchmetrics.F1(num_classes=23, multiclass=True, average='weighted'),\n",
    "            'f1_none' : torchmetrics.F1(num_classes=23, multiclass=True, average='none'),\n",
    "\n",
    "            'precision_micro' : torchmetrics.Precision(num_classes=23, multiclass=True, average='micro'),\n",
    "            'precision_macro' : torchmetrics.Precision(num_classes=23, multiclass=True, average='macro'),\n",
    "            'precision_weighted' : torchmetrics.Precision(num_classes=23, multiclass=True, average='weighted'),\n",
    "            'precision_none' : torchmetrics.Precision(num_classes=23, multiclass=True, average='none'),\n",
    "\n",
    "            'recall_micro' : torchmetrics.Recall(num_classes=23, multiclass=True, average='micro'),\n",
    "            'recall_macro' : torchmetrics.Recall(num_classes=23, multiclass=True, average='macro'),\n",
    "            'recall_weighted' : torchmetrics.Recall(num_classes=23, multiclass=True, average='weighted'),\n",
    "            'recall_none' : torchmetrics.Recall(num_classes=23, multiclass=True, average='none')\n",
    "        }) \n",
    "        \n",
    "    def fit(self, model, train_dataset, val_dataset):\n",
    "        \n",
    "        params_info = {\n",
    "            'learning_rate' : self.learning_rate,\n",
    "            'batch_size' : self.batch_size,\n",
    "            'n_epochs' : self.n_epochs\n",
    "        }\n",
    "        self.logger.run['params'] = params_info\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        #----------TRAINING\n",
    "\n",
    "        # Measure the total training time for the whole run.\n",
    "        total_t0 = time.time()\n",
    "\n",
    "        epochs = self.n_epochs\n",
    "\n",
    "        # Creation of Pytorch DataLoaders with shuffle=True for the traing phase\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        validation_dataloader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        #Adam algorithm optimized for tranfor architectures\n",
    "        optimizer = AdamW(model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Scaler for mixed precision\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        # Setup for training with gpu\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        model.to(device)\n",
    "\n",
    "        # For each epoch...\n",
    "        for epoch_i in range(0, epochs):\n",
    "            \n",
    "            # ========================================\n",
    "            #               Training\n",
    "            # ========================================\n",
    "            \n",
    "            # Perform one full pass over the training set.\n",
    "\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            print('Training...')\n",
    "\n",
    "            # Measure how long the training epoch takes.\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Reset the total loss for this epoch.\n",
    "            total_train_loss = 0\n",
    "\n",
    "            # Put the model into training mode: Dropout layers are active\n",
    "            model.train()\n",
    "            \n",
    "            # For each batch of training data...\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "                # Progress update every 40 batches.\n",
    "                if step % 10 == 0 and not step == 0:\n",
    "                    # Compute time in minutes.\n",
    "                    elapsed = format_time(time.time() - t0)\n",
    "                    \n",
    "                    # Report progress.\n",
    "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "                # Unpack this training batch from the dataloader. \n",
    "                #\n",
    "                #  copy each tensor to the GPU using the 'to()' method\n",
    "                #\n",
    "                # 'batch' contains three pytorch tensors:\n",
    "                #   [0]: input ids \n",
    "                #   [1]: attention masks\n",
    "                #   [2]: labels \n",
    "                b_input_ids = batch['input_ids'].to(device)\n",
    "                b_input_mask = batch['attention_mask'].to(device)\n",
    "                b_labels = batch['labels'].to(device)\n",
    "\n",
    "                # clear any previously calculated gradients before performing a\n",
    "                # backward pass\n",
    "                model.zero_grad()  \n",
    "\n",
    "\n",
    "                # Perform a forward pass in mixed precision\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(b_input_ids, \n",
    "                                    attention_mask=b_input_mask, \n",
    "                                    labels=b_labels)\n",
    "                \n",
    "                loss = outputs[0]\n",
    "                logits = outputs[1]\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                logits = logits.detach().cpu()\n",
    "                label_ids = b_labels.to('cpu')\n",
    "\n",
    "                batch_metric = self.metric_collection.update(logits, label_ids)\n",
    "                #print(batch_metric)\n",
    "\n",
    "                # Perform a backward pass to compute the gradients in MIXED precision\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Accumulate the training loss over all of the batches so that we can\n",
    "                # calculate the average loss at the end.\n",
    "                total_train_loss += loss.item()\n",
    "\n",
    "                # Unscales the gradients of optimizer's assigned params in-place before the gradient clipping\n",
    "                scaler.unscale_(optimizer)\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This helps and prevent the \"exploding gradients\" problem.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                # Update parameters and take a step using the computed gradient in MIXED precision\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "\n",
    "            # Compute the average loss over all of the batches.\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "            final_metrics = self.metric_collection.compute()\n",
    "            print(final_metrics)\n",
    "            \n",
    "            # Measure how long this epoch took.\n",
    "            training_time = format_time(time.time() - t0)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "            print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "            # ========================================\n",
    "            #               Validation\n",
    "            # ========================================\n",
    "            # After the completion of each training epoch, measure performance on\n",
    "            # the validation set.\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\")\n",
    "\n",
    "            self.metric_collection.reset()\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Put the model in evaluation mode: the dropout layers behave differently\n",
    "            model.eval()\n",
    "\n",
    "            total_val_loss = 0\n",
    "\n",
    "            # Evaluate data for one epoch\n",
    "            for batch in validation_dataloader:\n",
    "                \n",
    "                # Unpack this training batch from our dataloader. \n",
    "                #\n",
    "                # copy each tensor to the GPU using the 'to()' method\n",
    "                #\n",
    "                # 'batch' contains three pytorch tensors:\n",
    "                #   [0]: input ids \n",
    "                #   [1]: attention masks\n",
    "                #   [2]: labels \n",
    "                b_input_ids = batch['input_ids'].to(device)\n",
    "                b_input_mask = batch['attention_mask'].to(device)\n",
    "                b_labels = batch['labels'].to(device)\n",
    "                \n",
    "                # Tell pytorch not to bother with constructing the compute graph during\n",
    "                # the forward pass, since this is only needed for training.\n",
    "                with torch.no_grad():        \n",
    "\n",
    "                    # Forward pass, calculate logits\n",
    "                    # argmax(logits) = argmax(Softmax(logits))\n",
    "                    outputs = model(b_input_ids, \n",
    "                                        attention_mask=b_input_mask,\n",
    "                                        labels=b_labels)\n",
    "                    loss = outputs[0]\n",
    "                    logits = outputs[1]\n",
    "                    \n",
    "                # Accumulate the validation loss.\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                logits = logits.detach().cpu()\n",
    "                label_ids = b_labels.to('cpu')\n",
    "\n",
    "                # metric on current batch\n",
    "                batch_metric = self.metric_collection.update(logits.softmax(dim=1), label_ids)\n",
    "\n",
    "            # Report the final metrics for this validation phase.\n",
    "            # metric on all batches using custom accumulation from torchmetrics library\n",
    "\n",
    "            final_metrics = self.metric_collection.compute()\n",
    "            print('VALIDATION: ')\n",
    "            print(final_metrics)\n",
    "            # Compute the average loss over all of the batches.\n",
    "            avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "            \n",
    "            # Measure how long the validation run took.\n",
    "            validation_time = format_time(time.time() - t0)\n",
    "            \n",
    "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "            print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "        print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "https://app.neptune.ai/mibo8/Rep/e/REP-98\n",
      "Remember to stop your run once youâve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(2, 1e-5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_string = \"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_string, num_labels=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michele/anaconda3/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/tmp/ipykernel_19040/2032609219.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/home/michele/anaconda3/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Batch    10  of     47.    Elapsed: 0:00:18.\n",
      "  Batch    20  of     47.    Elapsed: 0:00:36.\n",
      "  Batch    30  of     47.    Elapsed: 0:00:54.\n",
      "  Batch    40  of     47.    Elapsed: 0:01:11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_macro': tensor(0.0774), 'accuracy_micro': tensor(0.1489), 'accuracy_none': tensor([   nan, 0.0000, 0.6250, 0.7500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2500, 0.0000,\n",
      "           nan, 0.0000, 0.0000, 0.0000, 0.0000]), 'accuracy_weighted': tensor(0.1489), 'f1_macro': tensor(0.0376), 'f1_micro': tensor(0.1489), 'f1_none': tensor([   nan, 0.0000, 0.3390, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.0000,\n",
      "           nan, 0.0000, 0.0000, 0.0000, 0.0000]), 'f1_weighted': tensor(0.0769), 'precision_macro': tensor(0.0379), 'precision_micro': tensor(0.1489), 'precision_none': tensor([   nan, 0.0000, 0.2326, 0.0638, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000,\n",
      "           nan, 0.0000, 0.0000, 0.0000, 0.0000]), 'precision_weighted': tensor(0.0636), 'recall_macro': tensor(0.0774), 'recall_micro': tensor(0.1489), 'recall_none': tensor([   nan, 0.0000, 0.6250, 0.7500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2500, 0.0000,\n",
      "           nan, 0.0000, 0.0000, 0.0000, 0.0000]), 'recall_weighted': tensor(0.1489)}\n",
      "\n",
      "  Average training loss: 3.070\n",
      "  Training epoch took: 0:01:24\n",
      "\n",
      "Running Validation...\n",
      "VALIDATION: \n",
      "{'accuracy_macro': tensor(0.2000), 'accuracy_micro': tensor(0.3333), 'accuracy_none': tensor([nan, 0., 1., nan, nan, nan, nan, nan, nan, nan, 0., nan, nan, 0., nan, nan, nan, nan,\n",
      "        nan, nan, 0., nan, nan]), 'accuracy_weighted': tensor(0.3333), 'f1_macro': tensor(0.1000), 'f1_micro': tensor(0.3333), 'f1_none': tensor([   nan, 0.0000, 0.5000,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan, 0.0000,    nan,    nan, 0.0000,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan, 0.0000,    nan,    nan]), 'f1_weighted': tensor(0.1667), 'precision_macro': tensor(0.0667), 'precision_micro': tensor(0.3333), 'precision_none': tensor([   nan, 0.0000, 0.3333,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "           nan, 0.0000,    nan,    nan, 0.0000,    nan,    nan,    nan,    nan,\n",
      "           nan,    nan, 0.0000,    nan,    nan]), 'precision_weighted': tensor(0.1111), 'recall_macro': tensor(0.2000), 'recall_micro': tensor(0.3333), 'recall_none': tensor([nan, 0., 1., nan, nan, nan, nan, nan, nan, nan, 0., nan, nan, 0., nan, nan, nan, nan,\n",
      "        nan, nan, 0., nan, nan]), 'recall_weighted': tensor(0.3333)}\n",
      "  Validation Loss: 2.37\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:01:24 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(loss, val_loss):\n",
    "  plt.figure(figsize=(10,6))\n",
    "  plt.xticks(range(1,len(loss)+1))\n",
    "  plt.plot(range(1,len(loss)+1), loss, label='train')\n",
    "  plt.plot(range(1,len(val_loss)+1), val_loss, label='val')\n",
    "  plt.title('loss')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = [0.4, 0.32, 0.26, 0.25]\n",
    "val_loss = [0.42, 0.36, 0.25, 0.29]\n",
    "\n",
    "plot_loss(loss,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
