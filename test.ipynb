{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info (NVML): NVML Shared Library Not Found. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/mibo8/Rep/e/REP-200\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./src')\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets.hyperion_dataset import HyperionDataset\n",
    "from trainers.mp_trainer import MPTrainer\n",
    "from utils.utils import seed_everything\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "seed_everything(4321)\n",
    "\n",
    "#cluster paths\n",
    "#df = pd.read_csv('./RepML/data/Splitted_full/Hyperion_train.csv', na_filter=False)\n",
    "#test_df = pd.read_csv('./RepML/data/Splitted_full/Hyperion_test.csv', na_filter=False)\n",
    "\n",
    "#local paths\n",
    "df = pd.read_csv('./data/Splitted_full/Hyperion_train.csv', na_filter=False)\n",
    "test_df = pd.read_csv('./data/Splitted_full/Hyperion_test.csv', na_filter=False)\n",
    "\n",
    "model_name = \"dbmdz/bert-base-italian-xxl-uncased\"\n",
    "test_dataset = HyperionDataset(test_df.head(100), model_name)\n",
    "\n",
    "learning_rate = 1e-5\n",
    "batch_size = 2\n",
    "n_epochs = 1\n",
    "\n",
    "trainer = MPTrainer(batch_size, learning_rate, n_epochs, torch.nn.NLLLoss())\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('MiBo/RepML')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n",
      "  Test Loss: 2.54\n",
      "  Test took: 0:00:13\n"
     ]
    }
   ],
   "source": [
    "pred, gt = trainer.test(model,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.hyperion_dataset import decode_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stralcio</th>\n",
       "      <th>Repertorio_corretto</th>\n",
       "      <th>Repertorio_predetto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aia ha anche affrontato il tema dei centri est...</td>\n",
       "      <td>anticipazione</td>\n",
       "      <td>descrizione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e il suo vaccino che mette a disposizione di a...</td>\n",
       "      <td>anticipazione</td>\n",
       "      <td>previsione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se anche le altre regioni facessero lo stesso...</td>\n",
       "      <td>anticipazione</td>\n",
       "      <td>possibilità</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se la sperimentazione riesce questo tipo di ta...</td>\n",
       "      <td>anticipazione</td>\n",
       "      <td>possibilità</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Veneto, #Zaia: “#Lockdown sarebbe una tragedia,</td>\n",
       "      <td>anticipazione</td>\n",
       "      <td>previsione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ma il vero problema sono i Bar dove tutti hann...</td>\n",
       "      <td>causa</td>\n",
       "      <td>contrapposizione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>e non possiamo intubare tanti pazienti perché ...</td>\n",
       "      <td>causa</td>\n",
       "      <td>giustificazione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Non si registrano grossi problemi se non quell...</td>\n",
       "      <td>causa</td>\n",
       "      <td>descrizione</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>«Non sono in quarantena perché ho incontrato ...</td>\n",
       "      <td>causa</td>\n",
       "      <td>sancire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>qualcuno allora gli chieda di spiegare perché,...</td>\n",
       "      <td>causa</td>\n",
       "      <td>deresponsabilizzazione</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Stralcio Repertorio_corretto  \\\n",
       "0   aia ha anche affrontato il tema dei centri est...       anticipazione   \n",
       "1   e il suo vaccino che mette a disposizione di a...       anticipazione   \n",
       "2    Se anche le altre regioni facessero lo stesso...       anticipazione   \n",
       "3   Se la sperimentazione riesce questo tipo di ta...       anticipazione   \n",
       "4    #Veneto, #Zaia: “#Lockdown sarebbe una tragedia,       anticipazione   \n",
       "..                                                ...                 ...   \n",
       "73  ma il vero problema sono i Bar dove tutti hann...               causa   \n",
       "74  e non possiamo intubare tanti pazienti perché ...               causa   \n",
       "75  Non si registrano grossi problemi se non quell...               causa   \n",
       "76   «Non sono in quarantena perché ho incontrato ...               causa   \n",
       "77  qualcuno allora gli chieda di spiegare perché,...               causa   \n",
       "\n",
       "       Repertorio_predetto  \n",
       "0              descrizione  \n",
       "1               previsione  \n",
       "2              possibilità  \n",
       "3              possibilità  \n",
       "4               previsione  \n",
       "..                     ...  \n",
       "73        contrapposizione  \n",
       "74         giustificazione  \n",
       "75             descrizione  \n",
       "76                 sancire  \n",
       "77  deresponsabilizzazione  \n",
       "\n",
       "[78 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "error_dict = {\n",
    "    'Stralcio' : df['Stralcio'].tolist(),\n",
    "    'Repertorio_corretto' : decode_labels(gt),\n",
    "    'Repertorio_predetto' : decode_labels(pred)\n",
    "}\n",
    "\n",
    "error_df = pd.DataFrame.from_dict(error_dict)\n",
    "error_df.drop(error_df[error_df.Repertorio_corretto == error_df.Repertorio_predetto].index, inplace=True)\n",
    "error_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run REP-200 received abort signal. Exiting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 4 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 4 operations synced, thanks for waiting!\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "error_df.to_csv('error.csv', index = False, header=True)\n",
    "trainer.logger.run[\"error_csv\"].upload('error.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "531bf1ddd0b9ee64f0e2ebd6527c520de4e2159f2ffcc26ba5e4b06431092b93"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
